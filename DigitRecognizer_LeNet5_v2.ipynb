{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DigitRecognizer LeNet5 v2\n",
    "#\n",
    "# CNN: LetNet5 v2\n",
    "#  - Conv1 f=5x5@30, Stride=1, Padding=Same\n",
    "#  - Conv2 f=3x3@16, Stride=1, Padding=Same\n",
    "#  - Dropout: 0.2\n",
    "#\n",
    "# Kaggle Scoring: 0.99042, Position #652 (Top 33%) (19/1/2018)\n",
    "#\n",
    "# Seed: 1\n",
    "# Epochs: 200\n",
    "# Batch Size: 200\n",
    "# Train metrics: {'recall': 1.0, 'global_step': 33600, 'precision': 1.0, 'accuracy': 1.0, 'loss': 5.616491e-05, 'f1_score': 1.0}\n",
    "# Val metrics: {'recall': 0.999735, 'global_step': 33600, 'precision': 0.99960256, 'accuracy': 0.99297619, 'loss': 0.054907657, 'f1_score': 0.99966877260234099}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "BATCH_SIZE = 200  #33.600 samples / 200 = 168 global_step / epoch => 168 * 200 epochs = 33.600 global_step\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = np.genfromtxt(\"train.csv\", delimiter=',', dtype=np.float32)\n",
    "data_test  = np.genfromtxt(\"test.csv\",  delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (42000, 784)\n",
      "X_test.shape: (28000, 784)\n",
      "y_train.shape: (42000, 1)\n",
      "y_train: [[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " ..., \n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 9.]]\n"
     ]
    }
   ],
   "source": [
    "#label,pixel0,pixel1,pixel2,..,pixel783\n",
    "X_train = data_train[1:,1:]   #(42000, 784)\n",
    "y_train = data_train[1:,0:1]  #(42000, 1)\n",
    "X_test  = data_test[1:,:]     #(28000, 784)\n",
    "\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_test.shape: {}\".format(X_test.shape))\n",
    "\n",
    "print(\"y_train.shape: {}\".format(y_train.shape))\n",
    "print(\"y_train: {}\".format(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (33600, 28, 28, 1)\n",
      "X_val.shape: (8400, 28, 28, 1)\n",
      "X_test.shape: (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((-1,28,28,1)) #(42000, 28, 28, 1)\n",
    "X_test  = X_test.reshape((-1,28,28,1)) #(42000, 28, 28, 1)\n",
    "\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test  = X_test / 255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=SEED)\n",
    "\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))  #(33600, 28, 28, 1)\n",
    "print(\"X_val.shape: {}\".format(X_val.shape))      #(8400, 28, 28, 1)\n",
    "print(\"X_test.shape: {}\".format(X_test.shape))    #(28000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model: Lenet-5 v2\n",
    "\n",
    "def cnn_model_fn( features, labels, mode):\n",
    "    # Kaggle Scoring: 0.99042, Position #652 (Top 33%) (19/1/2018)\n",
    "    # Seed: 1\n",
    "    # Epochs: 200\n",
    "    # Batch Size: 200\n",
    "    # Conv1: 30 filters, Conv2: filters size: 3x3, Dropout: 0.2\n",
    "    # Train metrics: {'recall': 1.0, 'global_step': 33600, 'precision': 1.0, 'accuracy': 1.0, 'loss': 5.616491e-05, 'f1_score': 1.0}\n",
    "    # Val metrics: {'recall': 0.999735, 'global_step': 33600, 'precision': 0.99960256, 'accuracy': 0.99297619, 'loss': 0.054907657, 'f1_score': 0.99966877260234099}\n",
    "    \n",
    "    # Conv1: 14x14@30\n",
    "    model = tf.layers.conv2d( \n",
    "        inputs = features[\"x\"], \n",
    "        filters = 30,\n",
    "        kernel_size = [5, 5],\n",
    "        strides = 1, \n",
    "        padding = \"SAME\",\n",
    "        activation = tf.nn.relu)\n",
    "    model = tf.layers.max_pooling2d( \n",
    "        inputs = model,\n",
    "        pool_size = [ 2, 2],\n",
    "        strides = 2)\n",
    "    \n",
    "    # Conv2: 7x7@16\n",
    "    model = tf.layers.conv2d( \n",
    "        inputs = model, \n",
    "        filters = 16, \n",
    "        kernel_size = [3, 3],\n",
    "        strides = 1, \n",
    "        padding = \"SAME\",\n",
    "        activation = tf.nn.relu)\n",
    "    model = tf.layers.max_pooling2d( \n",
    "        inputs = model,\n",
    "        pool_size = [ 2, 2],\n",
    "        strides = 2)\n",
    "\n",
    "    model = tf.layers.dropout( model, rate=0.2, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    model = tf.layers.flatten( inputs = model) # 784 nodes\n",
    "\n",
    "    # FC\n",
    "    model = tf.layers.dense( \n",
    "        inputs = model,\n",
    "        units = 120,\n",
    "        activation = tf.nn.relu)\n",
    "\n",
    "    model = tf.layers.dropout( model, rate=0.2, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "        \n",
    "    model = tf.layers.dense( \n",
    "        inputs = model,\n",
    "        units = 84,\n",
    "        activation = tf.nn.relu)\n",
    "\n",
    "    # Output (softmax)\n",
    "    logits = tf.layers.dense( model, 10, name = \"output_tensor\")\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax( logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax( logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # PREDICT\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions = predictions)\n",
    "    \n",
    "    \n",
    "    #Â TRAIN\n",
    "    onehot_labels = tf.one_hot( indices = tf.cast(labels, tf.int32), depth = 10)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( \n",
    "        logits=logits, \n",
    "        labels=onehot_labels), name=\"cost_tensor\")\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_op = tf.train.AdamOptimizer().minimize( cost, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = cost, train_op = train_op)\n",
    "    \n",
    "    \n",
    "    # EVAL\n",
    "    eval_metrics_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels = labels, \n",
    "            predictions = predictions[\"classes\"]),\n",
    "        \n",
    "        \"precision\": tf.metrics.precision(\n",
    "            labels = labels,\n",
    "            predictions = predictions[\"classes\"]),\n",
    "        \n",
    "        \"recall\": tf.metrics.recall(\n",
    "            labels = labels,\n",
    "            predictions = predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec( mode = mode, loss = cost, eval_metric_ops = eval_metrics_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model( X_train, y_train, X_val, y_val):\n",
    "    def f1_score( precision, recall):\n",
    "        return 2.0 / (precision**-1 + recall**-1)\n",
    "    \n",
    "    model = tf.estimator.Estimator(\n",
    "        model_fn = cnn_model_fn,\n",
    "        model_dir=\"/tmp/cnn_lenet5_v1_digits_model\")\n",
    "\n",
    "    model.train(\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x = {\"x\": X_train},\n",
    "            y = y_train,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            num_epochs = EPOCHS,\n",
    "            shuffle = True))\n",
    "\n",
    "    # Model performance\n",
    "    train_metrics = model.evaluate(\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x = {\"x\": X_train},\n",
    "            y = y_train,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            num_epochs = 1,\n",
    "            shuffle = False))\n",
    "\n",
    "    val_metrics = model.evaluate(\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x = {\"x\": X_val},\n",
    "            y = y_val,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            num_epochs = 1,\n",
    "            shuffle = True))\n",
    "\n",
    "    train_metrics[\"f1_score\"] = f1_score( train_metrics[\"precision\"], train_metrics[\"recall\"])\n",
    "    val_metrics[\"f1_score\"]   = f1_score( val_metrics[\"precision\"], val_metrics[\"recall\"])\n",
    "    \n",
    "    print(\">> Train metrics: %r\"% train_metrics)\n",
    "    print(\">> Val metrics: %r\"% val_metrics)\n",
    "    \n",
    "    return model, train_metrics, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_digits( model, X_test):\n",
    "    predictions = model.predict(\n",
    "        input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x = {\"x\": X_test},\n",
    "            num_epochs = 1,\n",
    "            shuffle = False))\n",
    "    \n",
    "    csv = open( \"digit_prediction.csv\", \"w\")\n",
    "    csv.write(\"ImageId,Label\\n\")\n",
    "    for i, pred in enumerate(predictions):\n",
    "        csv.write(\"{},{}\\n\".format( i+1, pred[\"classes\"]))\n",
    "    csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train metrics: {'recall': 1.0, 'global_step': 33600, 'precision': 1.0, 'accuracy': 1.0, 'loss': 5.616491e-05, 'f1_score': 1.0}\n",
      ">> Val metrics: {'recall': 0.999735, 'global_step': 33600, 'precision': 0.99960256, 'accuracy': 0.99297619, 'loss': 0.054907657, 'f1_score': 0.99966877260234099}\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.set_random_seed( SEED)\n",
    "    model, _, _ = train_model( X_train, y_train, X_val, y_val)\n",
    "    predict_digits( model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
